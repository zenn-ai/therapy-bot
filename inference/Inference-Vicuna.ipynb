{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ce74b6-77f4-449a-b25d-a4d9d7bb7b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 110\n",
      "CUDA SETUP: Loading binary /opt/conda/envs/py310/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda110.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py310/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /opt/conda did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Javascript, clear_output\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, GenerationConfig\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c55a859-abc4-4f50-852e-6c9e4ae37b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vicuna tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vicuna model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93df2fdff9cd4b42b50073f68a7ad7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"Loading transformer embeddings...\")\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "print(\"Loading Vicuna tokenizer\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"eachadea/vicuna-13b-1.1\")\n",
    "\n",
    "print(\"Loading Vicuna model\")\n",
    "model = LlamaForCausalLM.from_pretrained(\"eachadea/vicuna-13b-1.1\", load_in_8bit=True, device_map=\"auto\")\n",
    "# model = PeftModel.from_pretrained(model, \"kmnis/DocScribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4024d2d-abda-4dc9-a4b4-62a772adb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(question):\n",
    "    prompt = f\"\"\"### You are an AI mental health counselor with substantial training in therapeutic techniques.\n",
    "    Be sympathetic to the client and maintain a human-like conversation with the client. Adopt motivational interviewing.\n",
    "    The client should feel like they can count on you to support them through their mental health journey.\n",
    "    Don't make them feel like you are pushign them away.\n",
    "    Use your strong understanding of therapeutic techniques, to counsel the client on their struggles.\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "\n",
    "    generation_config = GenerationConfig(temperature=0.6, top_p=0.95, repetition_penalty=1.15)\n",
    "\n",
    "    generation_output = model.generate(input_ids=input_ids, generation_config=generation_config,\n",
    "                                       return_dict_in_generate=True, output_scores=False, max_new_tokens=200)\n",
    "\n",
    "    for out in generation_output.sequences:\n",
    "        out = tokenizer.decode(out)\n",
    "        out = out.split(\"### Answer:\")[1].split(\"</s>\")[0].strip()\n",
    "        print(out + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2f79b1c-42a6-49f2-8c97-17bc5061b882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Joe, it's nice to meet you. I understand that dealing with an eating disorder can be very difficult and challenging. It takes a lot of courage to seek help and support for this issue. Can you tell me more about what you have been experiencing?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Hey, I am Joe and am struggling with an eating disorder.\n",
    "\"\"\"\n",
    "get_results(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abca4a1-2cc3-4699-8fd6-9cd8cc25c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db198b62-5d88-49e6-9e8d-af0ce0f615b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ba13c-d4aa-44f7-87f3-a382f86b0259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c33b7d-05cf-4cd6-a021-32038a146bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298dd5ce-0f79-4feb-952a-662a922d5039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "py310",
   "name": "common-cu110.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m108"
  },
  "kernelspec": {
   "display_name": "Python (3.10)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
