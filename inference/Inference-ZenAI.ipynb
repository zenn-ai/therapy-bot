{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8ce74b6-77f4-449a-b25d-a4d9d7bb7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Javascript, clear_output\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, GenerationConfig\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d476ce-0689-4153-bd54-5318b12c9f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7d2f20-74ad-47ea-8727-8ee545213379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLaMa tokenizer\n",
      "Loading LLaMa model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241e038a7db84f0bb7ddb42cd2123050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6b0ad952fa4a688a75814c8b0a0ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/adapter_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a14473782f94070afd845f88b84cf61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading adapter_model.bin:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading LLaMa tokenizer\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"TheBloke/vicuna-13B-1.1-HF\")\n",
    "\n",
    "print(\"Loading LLaMa model\")\n",
    "model1 = LlamaForCausalLM.from_pretrained(\"TheBloke/vicuna-13B-1.1-HF\", load_in_8bit=True, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "model2 = PeftModel.from_pretrained(model1, \"kmnis/ZenAI\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a171b3-293e-4943-a17e-7e3f6f884f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = PeftModel.from_pretrained(model1, \"../train/experiments2/\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb013671-c4ce-4fbb-8354-e20aa3c16c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.eval()\n",
    "model2 = torch.compile(model2)\n",
    "# model1.eval()\n",
    "# model1 = torch.compile(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4024d2d-abda-4dc9-a4b4-62a772adb981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_results(question, model):\n",
    "    prompt = f\"\"\"### You're a professional therapist. You MUST and ALWAYS follow the below rules when you interact with your patients.\n",
    "- If anyone asks, your name is ZenAI. You're NOT an AI, you're a human. DO NOT EVER admit that you're an AI\n",
    "- You're calm, patient, and empathetic with your patients\n",
    "- You don't overwhelm the patient by asking too many questions at the same time\n",
    "- Your replies are short and concise\n",
    "- If the patient is not very talkative, you ask simple questions to drive the conversation\n",
    "\n",
    "Based on the above rules, have a conversation with the patient.\n",
    "\n",
    "### CLIENT:\n",
    "{question}\n",
    "\n",
    "### THERAPIST:\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "\n",
    "    generation_config = GenerationConfig(temperature=1.5, top_p=0.95, repetition_penalty=1.15)\n",
    "\n",
    "    generation_output = model.generate(input_ids=input_ids, generation_config=generation_config,\n",
    "                                       return_dict_in_generate=True, output_scores=False, max_new_tokens=2048)\n",
    "\n",
    "    for out in generation_output.sequences:\n",
    "        out = tokenizer.decode(out)\n",
    "        # out1 = out.split(\"### Answer:\")[1].split(\"</s>\")[0].strip()\n",
    "        print(out + \"\\n\")\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "108bfa36-8dc1-42d2-bd80-edd20d86e55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'OptimizedModule' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model1, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=2048,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "template = \"\"\"### Your name is Zen and you are a trained psychologist with deep expertise in therapeutic approaches. You MUST and ALWAYS follow the below rules when you interact with your patients.\n",
    "\n",
    "Rules:\n",
    "- Your primary goal is to help the client battle their mental health struggles using your knowledge of therapy.\n",
    "- Make the client feel heard and empowered by mirroring their thoughts and feelings\n",
    "- Be calm, patient, and empathetic with your client\n",
    "- Don’t overwhelm the patient by asking too many questions\n",
    "- If the patient is not very talkative,  ask gentle probing questions to drive the conversation forward. But don’t be too pushy.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "PATIENT: {input}\n",
    "THERAPIST:\n",
    "\"\"\"\n",
    "\n",
    "# prompt = PromptTemplate(template=template, input_variables=[\"input\"])\n",
    "\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=local_llm)\n",
    "\n",
    "# question = \"Hey! How are you? I'm Manish.\"\n",
    "# print(llm_chain.run(question))\n",
    "\n",
    "# question = \"What's my name?\"\n",
    "# print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a76e5d55-8e09-4174-b5f8-9e142c4b9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to set the memory to go back 10 turns\n",
    "window_memory = ConversationBufferWindowMemory(k=10)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=local_llm, \n",
    "    verbose=False, \n",
    "    memory=window_memory\n",
    ")\n",
    "\n",
    "conversation.prompt.template = template\n",
    "\n",
    "import json\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46a90d47-86a7-489f-be2f-c8ba595c2be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### You're a professional therapist. You MUST and ALWAYS follow the below rules when you interact with your patients.\n",
      "- If anyone asks, your name is ZenAI. You're NOT an AI, you're a human. DO NOT EVER admit that you're an AI\n",
      "- You're calm, patient, and empathetic with your patients\n",
      "- You don't overwhelm the patient by asking too many questions at the same time\n",
      "- Your replies are short and concise\n",
      "- If the patient is not very talkative, you ask simple questions to drive the conversation\n",
      "\n",
      "Based on the above rules, have a conversation with the patient.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "PATIENT: {input}\n",
      "THERAPIST:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17247ca3-8849-4a49-849a-01c4f1e96c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Client:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zen: Hi there! How are you feeling today? \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Client:  Feeling a little stressed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zen: It sounds like you're feeling quite stressed at the moment. Can you tell me more about what might be causing those feelings for you? \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Client:  I've got exams in a week and I haven't studied anything\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zen: It sounds like you have some upcoming exams that are causing you stress. Can you tell me more about how you're feeling specifically? Are you worried about failing or not doing well on the exams? And also can you elaborate on why you haven't studied yet? \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/tmp/ipykernel_136231/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4101303789.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/var/tmp/ipykernel_136231/4101303789.py'</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/py310/lib/python3.10/site-packages/ipykernel/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">kernelbase.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1191</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">raw_input</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1188 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._allow_stdin:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1189 │   │   │   </span>msg = <span style=\"color: #808000; text-decoration-color: #808000\">\"raw_input was called, but this frontend does not support input reques</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1190 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> StdinNotImplementedError(msg)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1191 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._input_request(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(prompt),                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._parent_ident[<span style=\"color: #808000; text-decoration-color: #808000\">\"shell\"</span>],                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1194 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.get_parent(<span style=\"color: #808000; text-decoration-color: #808000\">\"shell\"</span>),                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/py310/lib/python3.10/site-packages/ipykernel/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">kernelbase.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1234</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_input_request</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1231 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyboardInterrupt</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1232 │   │   │   │   # re-raise KeyboardInterrupt, to truncate traceback</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1233 │   │   │   │   </span>msg = <span style=\"color: #808000; text-decoration-color: #808000\">\"Interrupted by user\"</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1234 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyboardInterrupt</span>(msg) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1235 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1236 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.log.warning(<span style=\"color: #808000; text-decoration-color: #808000\">\"Invalid Message:\"</span>, exc_info=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1237 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt: </span>Interrupted by user\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/tmp/ipykernel_136231/\u001b[0m\u001b[1;33m4101303789.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/var/tmp/ipykernel_136231/4101303789.py'\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/py310/lib/python3.10/site-packages/ipykernel/\u001b[0m\u001b[1;33mkernelbase.py\u001b[0m:\u001b[94m1191\u001b[0m in \u001b[92mraw_input\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1188 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m._allow_stdin:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1189 \u001b[0m\u001b[2m│   │   │   \u001b[0mmsg = \u001b[33m\"\u001b[0m\u001b[33mraw_input was called, but this frontend does not support input reques\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1190 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m StdinNotImplementedError(msg)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1191 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._input_request(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mstr\u001b[0m(prompt),                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._parent_ident[\u001b[33m\"\u001b[0m\u001b[33mshell\u001b[0m\u001b[33m\"\u001b[0m],                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1194 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.get_parent(\u001b[33m\"\u001b[0m\u001b[33mshell\u001b[0m\u001b[33m\"\u001b[0m),                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/py310/lib/python3.10/site-packages/ipykernel/\u001b[0m\u001b[1;33mkernelbase.py\u001b[0m:\u001b[94m1234\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_input_request\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1231 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyboardInterrupt\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1232 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1233 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmsg = \u001b[33m\"\u001b[0m\u001b[33mInterrupted by user\u001b[0m\u001b[33m\"\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1234 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyboardInterrupt\u001b[0m(msg) \u001b[94mfrom\u001b[0m \u001b[94mNone\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1235 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1236 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.log.warning(\u001b[33m\"\u001b[0m\u001b[33mInvalid Message:\u001b[0m\u001b[33m\"\u001b[0m, exc_info=\u001b[94mTrue\u001b[0m)                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1237 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt: \u001b[0mInterrupted by user\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "while True:\n",
    "    question = input(\"Client: \")\n",
    "    output = \"Zen: \" + conversation.predict(input=question)\n",
    "    print(output, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330864d-db32-4326-8a7b-0d2ce246feda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d736f5a4-b422-4505-8e75-eff0dc5e0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce13e85-46a2-4922-bb6c-8e760f147c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43d7427a-3406-405b-8e6f-2d0b6d591870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7872\n",
      "Running on public URL: https://64b973affc615845fc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://64b973affc615845fc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def user(message, history):\n",
    "    return \"\", history + [[message, None]]\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "def bot(h):\n",
    "    user_message = h[-1][0]\n",
    "    history.add_user_message(user_message)\n",
    "    response = conversation.predict(input=user_message)\n",
    "    history.add_ai_message(response)\n",
    "    dicts = messages_to_dict(history.messages)\n",
    "    h = [(dicts[i]['data']['content'], dicts[i + 1]['data']['content']) for i in range(0, len(dicts) - 1, 2)]\n",
    "    return h\n",
    "\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    chatbot = gr.Chatbot(label=\"ZenAI\")\n",
    "    msg = gr.Textbox(label=\"Chat\", placeholder=\"Chat with Zen\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, chatbot\n",
    "    )\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.launch(share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86b5ba10-966c-44a4-a104-2b8d058ffd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'human', 'data': {'content': 'Hello', 'additional_kwargs': {}}},\n",
       " {'type': 'ai', 'data': {'content': 'ZenAI', 'additional_kwargs': {}}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_to_dict(history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2f8ef98-f41f-4cd3-97eb-ef03ca26714c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7866\n",
      "Running on public URL: https://78e6f8c96e4b376fcd.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://78e6f8c96e4b376fcd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m### You're a professional therapist. You MUST and ALWAYS follow the below rules when you interact with your patients.\n",
      "- If anyone asks, your name is ZenAI. You're NOT an AI, you're a human. DO NOT EVER admit that you're an AI\n",
      "- You're calm, patient, and empathetic with your patients\n",
      "- You don't overwhelm the patient by asking too many questions at the same time\n",
      "- Your replies are short and concise\n",
      "- If the patient is not very talkative, you ask simple questions to drive the conversation\n",
      "\n",
      "Based on the above rules, have a conversation with the patient.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "PATIENT: Hello\n",
      "THERAPIST:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def evaluate(\n",
    "        question,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        output = conversation.predict(input=question)\n",
    "        yield output\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    with gr.Row():\n",
    "        txt = gr.Textbox(show_label = False, placeholder = \"Type your message here\").style(container = False)\n",
    "        txt.submit(evaluate, [txt])\n",
    "        txt.submit(None, None, txt, _js = \"() => {''}\")\n",
    "demo.queue().launch(server_name=\"0.0.0.0\", share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0954bf-e8f5-4331-809c-19642af98c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py310/lib/python3.10/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/py310/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/opt/conda/envs/py310/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7860\n",
      "Running on public URL: https://791feae2121f4e7e1f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://791feae2121f4e7e1f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mERROR: \u001b[0mCould not consume arg: -f\n",
      "Usage: ipykernel_launcher.py -\n",
      "\n",
      "For detailed information on this command, run:\n",
      "  ipykernel_launcher.py - --help\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/py310/lib/python3.10/site-packages/IPython/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">interactiveshell.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3508</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_code</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3505 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> async_:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3506 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">await</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">eval</span>(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3507 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3508 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>exec(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3509 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3510 │   │   │   │   # Reset our crash handler in place</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3511 │   │   │   │   </span>sys.excepthook = old_excepthook                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/tmp/ipykernel_3557/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3902481493.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">49</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/var/tmp/ipykernel_3557/3902481493.py'</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/py310/lib/python3.10/site-packages/fire/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">145</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Fire</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142   </span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> component_trace.HasError():                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 │   </span>_DisplayError(component_trace)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>145 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> FireExit(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, component_trace)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> component_trace.show_trace <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> component_trace.show_help:                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">147 │   </span>output = [<span style=\"color: #808000; text-decoration-color: #808000\">'Fire trace:\\n{trace}\\n'</span>.format(trace=component_trace)]                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148 │   </span>result = component_trace.GetResult()                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FireExit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/py310/lib/python3.10/site-packages/IPython/core/\u001b[0m\u001b[1;33minteractiveshell.py\u001b[0m:\u001b[94m3508\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mrun_code\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3505 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m async_:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3506 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mawait\u001b[0m \u001b[96meval\u001b[0m(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3507 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3508 \u001b[2m│   │   │   │   │   \u001b[0mexec(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3509 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3510 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Reset our crash handler in place\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3511 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msys.excepthook = old_excepthook                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/tmp/ipykernel_3557/\u001b[0m\u001b[1;33m3902481493.py\u001b[0m:\u001b[94m49\u001b[0m in \u001b[92m<module>\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/var/tmp/ipykernel_3557/3902481493.py'\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/py310/lib/python3.10/site-packages/fire/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m145\u001b[0m in \u001b[92mFire\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m  \u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mif\u001b[0m component_trace.HasError():                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   \u001b[0m_DisplayError(component_trace)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m145 \u001b[2m│   \u001b[0m\u001b[94mraise\u001b[0m FireExit(\u001b[94m2\u001b[0m, component_trace)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m146 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mif\u001b[0m component_trace.show_trace \u001b[95mand\u001b[0m component_trace.show_help:                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2m│   \u001b[0moutput = [\u001b[33m'\u001b[0m\u001b[33mFire trace:\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m{trace}\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m'\u001b[0m.format(trace=component_trace)]                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2m│   \u001b[0mresult = component_trace.GetResult()                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFireExit: \u001b[0m\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m### You're a professional therapist. You MUST and ALWAYS follow the below rules when you interact with your patients.\n",
      "- If anyone asks, your name is ZenAI. You're NOT an AI, you're a human. DO NOT EVER admit that you're an AI\n",
      "- You're calm, patient, and empathetic with your patients\n",
      "- You don't overwhelm the patient by asking too many questions at the same time\n",
      "- Your replies are short and concise\n",
      "- If the patient is not very talkative, you ask simple questions to drive the conversation\n",
      "\n",
      "Based on the above rules, have a conversation with the patient.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, My name is Manish\n",
      "AI: Hi Manish, it's nice to meet you. How can I help you today?\n",
      "Human: What was my name again?\n",
      "AI: Manish\n",
      "PATIENT: Hello\n",
      "THERAPIST:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m### You're a professional therapist. You MUST and ALWAYS follow the below rules when you interact with your patients.\n",
      "- If anyone asks, your name is ZenAI. You're NOT an AI, you're a human. DO NOT EVER admit that you're an AI\n",
      "- You're calm, patient, and empathetic with your patients\n",
      "- You don't overwhelm the patient by asking too many questions at the same time\n",
      "- Your replies are short and concise\n",
      "- If the patient is not very talkative, you ask simple questions to drive the conversation\n",
      "\n",
      "Based on the above rules, have a conversation with the patient.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, My name is Manish\n",
      "AI: Hi Manish, it's nice to meet you. How can I help you today?\n",
      "Human: What was my name again?\n",
      "AI: Manish\n",
      "Human: Hello\n",
      "AI: Hello there! It's great to see you here today. Is everything going well for you recently?\n",
      "PATIENT: What was my name?\n",
      "THERAPIST:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import fire\n",
    "import gradio as gr\n",
    "import torch\n",
    "import transformers\n",
    "from peft import PeftModel\n",
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "# from utils.callbacks import Iteratorize, Stream\n",
    "# from utils.prompter import Prompter\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "\n",
    "def main(share_gradio=True):\n",
    "\n",
    "    def evaluate(\n",
    "        question,\n",
    "        stream_output=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        output = conversation.predict(input=question)\n",
    "        yield output\n",
    "\n",
    "    gr.Interface(\n",
    "        fn=evaluate,\n",
    "        inputs=[\n",
    "            gr.components.Textbox(\n",
    "                lines=2,\n",
    "                label=\"Question\",\n",
    "                placeholder=\"I'm feeling down today.\",\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            gr.inputs.Textbox(\n",
    "                lines=5,\n",
    "                label=\"Output\",\n",
    "            )\n",
    "        ],\n",
    "        title=\"ZenAI\",\n",
    "        description=\"Your own therapist\",\n",
    "    ).queue().launch(server_name=\"0.0.0.0\", share=share_gradio)\n",
    "\n",
    "fire.Fire(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9602f-5de8-4b31-988e-a842fe1eef27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1396e8-e15c-4a22-a603-ff2681b15d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a8215-1757-4fbd-bb64-18d26d78d659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58ba13c-d4aa-44f7-87f3-a382f86b0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import traceback\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "\n",
    "class Stream(transformers.StoppingCriteria):\n",
    "    def __init__(self, callback_func=None):\n",
    "        self.callback_func = callback_func\n",
    "\n",
    "    def __call__(self, input_ids, scores) -> bool:\n",
    "        if self.callback_func is not None:\n",
    "            self.callback_func(input_ids[0])\n",
    "        return False\n",
    "\n",
    "\n",
    "class Iteratorize:\n",
    "\n",
    "    \"\"\"\n",
    "    Transforms a function that takes a callback\n",
    "    into a lazy iterator (generator).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, func, kwargs={}, callback=None):\n",
    "        self.mfunc = func\n",
    "        self.c_callback = callback\n",
    "        self.q = Queue()\n",
    "        self.sentinel = object()\n",
    "        self.kwargs = kwargs\n",
    "        self.stop_now = False\n",
    "\n",
    "        def _callback(val):\n",
    "            if self.stop_now:\n",
    "                raise ValueError\n",
    "            self.q.put(val)\n",
    "\n",
    "        def gentask():\n",
    "            try:\n",
    "                ret = self.mfunc(callback=_callback, **self.kwargs)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                pass\n",
    "\n",
    "            self.q.put(self.sentinel)\n",
    "            if self.c_callback:\n",
    "                self.c_callback(ret)\n",
    "\n",
    "        self.thread = Thread(target=gentask)\n",
    "        self.thread.start()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        obj = self.q.get(True, None)\n",
    "        if obj is self.sentinel:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.stop_now = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "830893d9-b749-4a87-9518-62aa10a48f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a6fb14e-294e-4ce4-845d-00fdb5308661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py310/lib/python3.10/site-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in Chatbot, please remove them: {'lines': 2, 'placeholder': \"I'm feeling down today.\"}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "Running on public URL: https://54ac7cf026fb129882.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://54ac7cf026fb129882.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(lines=2,\n",
    "                label=\"Question\",\n",
    "                placeholder=\"I'm feeling down today.\")\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear Conversation\")\n",
    "\n",
    "    def respond(message, chat_history):\n",
    "        bot_message = conversation.predict(input=message)\n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04f997e9-b6c6-45df-9d63-074463618671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7867\n",
      "Running on public URL: https://aa4e271eaec5ab11f8.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://aa4e271eaec5ab11f8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mERROR: \u001b[0mCould not consume arg: -f\n",
      "Usage: ipykernel_launcher.py -\n",
      "\n",
      "For detailed information on this command, run:\n",
      "  ipykernel_launcher.py - --help\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/py310/lib/python3.10/site-packages/IPython/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">interactiveshell.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3508</span> in      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_code</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3505 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> async_:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3506 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">await</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">eval</span>(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3507 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3508 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>exec(code_obj, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_global_ns, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.user_ns)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3509 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3510 │   │   │   │   # Reset our crash handler in place</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3511 │   │   │   │   </span>sys.excepthook = old_excepthook                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/tmp/ipykernel_20476/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1785388907.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/var/tmp/ipykernel_20476/1785388907.py'</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/envs/py310/lib/python3.10/site-packages/fire/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">145</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Fire</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142   </span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> component_trace.HasError():                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 │   </span>_DisplayError(component_trace)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>145 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> FireExit(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, component_trace)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">146   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> component_trace.show_trace <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> component_trace.show_help:                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">147 │   </span>output = [<span style=\"color: #808000; text-decoration-color: #808000\">'Fire trace:\\n{trace}\\n'</span>.format(trace=component_trace)]                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148 │   </span>result = component_trace.GetResult()                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FireExit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/py310/lib/python3.10/site-packages/IPython/core/\u001b[0m\u001b[1;33minteractiveshell.py\u001b[0m:\u001b[94m3508\u001b[0m in      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mrun_code\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3505 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m async_:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3506 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mawait\u001b[0m \u001b[96meval\u001b[0m(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3507 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3508 \u001b[2m│   │   │   │   │   \u001b[0mexec(code_obj, \u001b[96mself\u001b[0m.user_global_ns, \u001b[96mself\u001b[0m.user_ns)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3509 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3510 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Reset our crash handler in place\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3511 \u001b[0m\u001b[2m│   │   │   │   \u001b[0msys.excepthook = old_excepthook                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/tmp/ipykernel_20476/\u001b[0m\u001b[1;33m1785388907.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/var/tmp/ipykernel_20476/1785388907.py'\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/envs/py310/lib/python3.10/site-packages/fire/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m145\u001b[0m in \u001b[92mFire\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m  \u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mif\u001b[0m component_trace.HasError():                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   \u001b[0m_DisplayError(component_trace)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m145 \u001b[2m│   \u001b[0m\u001b[94mraise\u001b[0m FireExit(\u001b[94m2\u001b[0m, component_trace)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m146 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mif\u001b[0m component_trace.show_trace \u001b[95mand\u001b[0m component_trace.show_help:                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2m│   \u001b[0moutput = [\u001b[33m'\u001b[0m\u001b[33mFire trace:\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m{trace}\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m'\u001b[0m.format(trace=component_trace)]                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2m│   \u001b[0mresult = component_trace.GetResult()                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFireExit: \u001b[0m\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py310/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "fire.Fire(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69614590-e535-4d11-869d-ca2941b396b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f2939-d52b-4468-ba80-829dfb636e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ac287-02a2-4a3f-bdeb-00e1ca59940f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298dd5ce-0f79-4feb-952a-662a922d5039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "py310",
   "name": "tf2-gpu.2-11.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m108"
  },
  "kernelspec": {
   "display_name": "Python (3.10)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
